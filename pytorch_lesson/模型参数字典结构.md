éå¸¸å¥½çš„é—®é¢˜ ğŸ‘
è¿™æ˜¯å¾ˆå¤šäººå¼€å§‹ç”¨ PyTorch è®­ç»ƒæ¨¡å‹ã€ä¿å­˜/åŠ è½½ checkpoint æ—¶éƒ½ä¼šé‡åˆ°çš„ä¸€ä¸ªå…³é”®ç‚¹ã€‚
â€”â€”**`model.state_dict()`** å’Œ **`optimizer.state_dict()`** éƒ½æ˜¯ä¿å­˜è®­ç»ƒçŠ¶æ€çš„å­—å…¸ï¼Œä½†å®ƒä»¬ç»“æ„å®Œå…¨ä¸åŒã€ä½œç”¨ä¹Ÿä¸åŒã€‚

ä¸‹é¢æˆ‘å¸®ä½ ç³»ç»Ÿã€ç›´è§‚åœ°å¯¹æ¯”è¿™ä¸¤ä¸ªç»“æ„ ğŸ‘‡

---

## ğŸ§© ä¸€ã€ç»“æ„å¯¹æ¯”æ€»è§ˆ

| å¯¹è±¡                           | æ¥æº     | ä¸»è¦å†…å®¹                     | ä¸»è¦ä½œç”¨                         |
| ---------------------------- | ------ | ------------------------ | ---------------------------- |
| **`model.state_dict()`**     | ç¥ç»ç½‘ç»œæ¨¡å‹ | å±‚å â†’ æƒé‡å¼ é‡ (`tensor`)     | ä¿å­˜æ¨¡å‹çš„**å¯å­¦ä¹ å‚æ•°ï¼ˆweights/biasï¼‰** |
| **`optimizer.state_dict()`** | ä¼˜åŒ–å™¨å¯¹è±¡  | å‚æ•°çŠ¶æ€ï¼ˆåŠ¨é‡ã€ä¸€é˜¶çŸ©ã€äºŒé˜¶çŸ©ç­‰ï¼‰+ å‚æ•°ç»„ä¿¡æ¯ | ä¿å­˜ä¼˜åŒ–å™¨çš„**åŠ¨é‡ã€å­¦ä¹ ç‡ç­‰è®­ç»ƒçŠ¶æ€**        |

---

## ğŸ§  äºŒã€`model.state_dict()` ç¤ºä¾‹

å‡è®¾æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ¨¡å‹ï¼š

```python
import torch
import torch.nn as nn

model = nn.Sequential(
    nn.Linear(10, 5),
    nn.ReLU(),
    nn.Linear(5, 2)
)
```

æ‰§è¡Œï¼š

```python
print(model.state_dict())
```

è¾“å‡ºç»“æ„ï¼ˆéƒ¨åˆ†ï¼‰ï¼š

```python
OrderedDict([
    ('0.weight', tensor([[...], [...]])),   # Linear(10,5) çš„æƒé‡
    ('0.bias', tensor([...])),              # Linear(10,5) çš„åç½®
    ('2.weight', tensor([[...], [...]])),   # Linear(5,2) çš„æƒé‡
    ('2.bias', tensor([...]))               # Linear(5,2) çš„åç½®
])
```

> âœ… `state_dict()` æ˜¯ä¸€ä¸ª `OrderedDict`
> âœ… key æ˜¯å±‚å
> âœ… value æ˜¯å¯¹åº”çš„æƒé‡/åç½®å¼ é‡
> âœ… é€šå¸¸åªåœ¨ä¿å­˜æ¨¡å‹å‚æ•°æ—¶ä½¿ç”¨ï¼ˆæ— å…³ä¼˜åŒ–å™¨ï¼‰

---

### âœ… å¸¸ç”¨ä¿å­˜ / åŠ è½½

ä¿å­˜ï¼š

```python
torch.save(model.state_dict(), 'model.pth')
```

åŠ è½½ï¼š

```python
model.load_state_dict(torch.load('model.pth'))
```

---

## âš™ï¸ ä¸‰ã€`optimizer.state_dict()` ç¤ºä¾‹

åˆ›å»ºä¼˜åŒ–å™¨ï¼š

```python
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

æ‰§è¡Œï¼š

```python
print(optimizer.state_dict())
```

è¾“å‡ºç»“æ„ï¼ˆå…¸å‹ï¼‰ï¼š

```python
{
  'state': {
    0: {                   # å¯¹åº”ç¬¬ä¸€ä¸ªå‚æ•° (Linear(10,5).weight)
        'exp_avg': tensor(...),     # ä¸€é˜¶åŠ¨é‡ (momentum)
        'exp_avg_sq': tensor(...),  # äºŒé˜¶åŠ¨é‡ (variance)
        'step': 20                  # å·²æ›´æ–°æ¬¡æ•°
    },
    1: { ... },             # ç¬¬äºŒä¸ªå‚æ•° (Linear(10,5).bias)
    2: { ... },             # ...
    3: { ... }
  },
  'param_groups': [
    {
      'params': [0, 1, 2, 3],  # è¿™äº› index å¯¹åº”ä¸Šé¢çš„ state keys
      'lr': 0.001,
      'betas': (0.9, 0.999),
      'eps': 1e-08,
      'weight_decay': 0,
      'amsgrad': False
    }
  ]
}
```

---

## ğŸ§© å››ã€ä¸¤è€…çš„æ ¸å¿ƒåŒºåˆ«

| å¯¹æ¯”é¡¹        | `model.state_dict()`           | `optimizer.state_dict()`        |
| ---------- | ------------------------------ | ------------------------------- |
| å†…å®¹         | æ¨¡å‹æƒé‡ï¼ˆweight/biasï¼‰              | åŠ¨é‡ã€å­¦ä¹ ç‡ã€å‚æ•°ç»„ä¿¡æ¯                    |
| key        | å±‚åï¼ˆå¦‚ â€œlayer1.weightâ€ï¼‰          | å‚æ•°ç´¢å¼•å·ï¼ˆintï¼‰                      |
| ç±»å‹         | `OrderedDict`                  | æ™®é€š dictï¼ˆå« state + param_groupsï¼‰ |
| æ˜¯å¦ä¸æ¨¡å‹ç»“æ„ç»‘å®š  | âœ… æ˜¯                            | âš ï¸ å¦ï¼ˆä»…ä¾èµ–å‚æ•°é¡ºåºï¼‰                   |
| å¸¸ç”¨äº        | ä¿å­˜/åŠ è½½æ¨¡å‹å‚æ•°                      | ä¿å­˜/åŠ è½½è®­ç»ƒè¿›åº¦                       |
| åŠ è½½æ–¹å¼       | `model.load_state_dict()`      | `optimizer.load_state_dict()`   |
| ä¿å­˜æ–‡ä»¶       | `model.pth` / `checkpoint.pth` | é€šå¸¸æ”¾å…¥ checkpoint ä¸€èµ·ä¿å­˜            |
| æ˜¯å¦ä¾èµ–æ¨¡å‹å‚æ•°é¡ºåº | å¦                              | æ˜¯ï¼ˆå¿…é¡»åŒ¹é… model.parameters() é¡ºåºï¼‰   |

---

## ğŸ“¦ äº”ã€å…¸å‹çš„ checkpoint ç»“æ„ï¼ˆä¸¤è€…ä¸€èµ·ä¿å­˜ï¼‰

å®Œæ•´ä¿å­˜è®­ç»ƒçŠ¶æ€æ—¶ï¼Œé€šå¸¸æˆ‘ä»¬ä¼šä¿å­˜äºŒè€…ï¼š

```python
checkpoint = {
    'epoch': epoch,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'best_accuracy': best_acc,
}
torch.save(checkpoint, 'checkpoint.pth')
```

åŠ è½½æ—¶ï¼š

```python
checkpoint = torch.load('checkpoint.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
```

---

## ğŸ§  å…­ã€ä¸ºä»€ä¹ˆæœ‰æ—¶åŠ è½½ optimizer ä¼šå¤±è´¥ï¼Ÿ

å› ä¸ºï¼š

* `optimizer.state_dict()` é‡Œçš„ param ç´¢å¼•æ˜¯æŒ‰æ¨¡å‹å‚æ•°é¡ºåºç¼–å·çš„ï¼›
* å¦‚æœä½ æ¢äº†æ¨¡å‹ç»“æ„ã€æˆ–è€…å†»ç»“/è§£å†»å±‚ï¼Œå‚æ•°æ•°é‡æˆ–é¡ºåºå°±å˜äº†ï¼›
* è¿™æ—¶ `optimizer.load_state_dict()` å°±æ‰¾ä¸åˆ°å¯¹åº”ç´¢å¼• â†’ æŠ¥é”™ã€‚

æ‰€ä»¥å¾ˆå¤šäººé€‰æ‹©ï¼š

> âœ… åŠ è½½ optimizer å‰å…ˆé‡æ–°æ„å»ºåŒæ ·çš„æ¨¡å‹ç»“æ„ï¼›
> æˆ–è€…åªåŠ è½½ modelï¼Œä¸åŠ è½½ optimizerï¼ˆé‡æ–°è®­ç»ƒæ—¶é‡ç½®åŠ¨é‡ï¼‰ã€‚

---

## ğŸ§­ ä¸ƒã€æ€»ç»“ä¸€å¥è¯è®°å¿†

| å¯¹è±¡                       | å«ä¹‰                   |
| ------------------------ | -------------------- |
| `model.state_dict()`     | å­˜â€œä½ å­¦åˆ°çš„çŸ¥è¯†â€ï¼ˆç½‘ç»œæƒé‡ï¼‰      |
| `optimizer.state_dict()` | å­˜â€œä½ å­¦ä¹ çš„èŠ‚å¥â€ï¼ˆåŠ¨é‡ã€æ­¥æ•°ã€å­¦ä¹ ç‡ï¼‰ |

---



æ˜ç™½ï¼Œä½ æƒ³çœ‹ PyTorch æ¨¡å‹çš„ **å­—å…¸ç»“æ„**ï¼Œä¹Ÿå°±æ˜¯ `model.state_dict()` çš„å†…éƒ¨ç»„ç»‡æ–¹å¼ã€‚æˆ‘ä»¬æ¥è¯¦ç»†åˆ†æã€‚

---

## 1ï¸âƒ£ åŸºæœ¬æ¦‚å¿µ

* `model.state_dict()` è¿”å›ä¸€ä¸ª **æœ‰åºå­—å…¸**ï¼ˆ`OrderedDict`ï¼‰ï¼ŒåŒ…å«ï¼š

  1. **æ¨¡å‹çš„æ‰€æœ‰å‚æ•°**ï¼ˆweightsã€biasesï¼‰
  2. **æŒä¹…åŒ–ç¼“å†²**ï¼ˆbuffersï¼Œæ¯”å¦‚ BatchNorm çš„ running_mean å’Œ running_varï¼‰
* key æ˜¯ **æ¨¡å—è·¯å¾„ + å‚æ•°å**ï¼Œvalue æ˜¯ **å¯¹åº”çš„ tensor**ã€‚

---

## 2ï¸âƒ£ ç¤ºä¾‹ï¼šç®€å•ä¸¤å±‚ç½‘ç»œ

```python
import torch
import torch.nn as nn

class SimpleNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(10, 20)
        self.bn1 = nn.BatchNorm1d(20)
        self.fc2 = nn.Linear(20, 5)

model = SimpleNet()
state_dict = model.state_dict()
```

---

## 3ï¸âƒ£ æ‰“å°ç»“æ„

```python
for k, v in state_dict.items():
    print(k, v.shape)
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
fc1.weight torch.Size([20, 10])
fc1.bias   torch.Size([20])
bn1.weight torch.Size([20])
bn1.bias   torch.Size([20])
bn1.running_mean torch.Size([20])
bn1.running_var  torch.Size([20])
fc2.weight torch.Size([5, 20])
fc2.bias   torch.Size([5])
```

---

## 4ï¸âƒ£ è§£é‡Š

| key                                    | å«ä¹‰                     |
| -------------------------------------- | ---------------------- |
| `fc1.weight`                           | ç¬¬ä¸€å±‚ Linear çš„æƒé‡çŸ©é˜µ       |
| `fc1.bias`                             | ç¬¬ä¸€å±‚ Linear çš„åç½®         |
| `bn1.weight` / `bn1.bias`              | BatchNorm çš„å¯è®­ç»ƒå‚æ•° Î³ å’Œ Î² |
| `bn1.running_mean` / `bn1.running_var` | BatchNorm çš„ç»Ÿè®¡é‡ï¼ˆç¼“å†²åŒºï¼‰    |
| `fc2.weight` / `fc2.bias`              | ç¬¬äºŒå±‚ Linear çš„æƒé‡å’Œåç½®      |

* **æ³¨æ„**ï¼šä¸æ˜¯æ‰€æœ‰ tensor éƒ½æ˜¯å¯è®­ç»ƒçš„ã€‚

  * `requires_grad=True` â†’ å¯è®­ç»ƒå‚æ•°ï¼ˆoptimizer ä¼šæ›´æ–°ï¼‰
  * `requires_grad=False` â†’ å†»ç»“å‚æ•°ï¼Œä¸ä¼šæ›´æ–°

---

## 5ï¸âƒ£ å¯¹æ¯” optimizer.state_dict()

| é¡¹     | model.state_dict() | optimizer.state_dict() |
| ----- | ------------------ | ---------------------- |
| å†…å®¹    | æ¨¡å‹æƒé‡å’Œç¼“å†²            | ä¼˜åŒ–å™¨å†…éƒ¨çŠ¶æ€ï¼ˆåŠ¨é‡ã€å¹³æ–¹æ¢¯åº¦ç­‰ï¼‰      |
| key   | å­—ç¬¦ä¸²æ¨¡å—å             | å‚æ•°ç´¢å¼•ï¼ˆæˆ– param_groupï¼‰    |
| value | Tensor             | dictï¼ˆåŠ¨é‡ã€æ¢¯åº¦å¹³æ–¹ç­‰ï¼‰         |
| ç”¨é€”    | ä¿å­˜/åŠ è½½æ¨¡å‹            | ä¿å­˜/åŠ è½½è®­ç»ƒè¿›åº¦              |

---

## 6ï¸âƒ£ ä¿å­˜å’ŒåŠ è½½æ¨¡å‹

```python
# ä¿å­˜
torch.save(model.state_dict(), "model.pth")

# åŠ è½½
model.load_state_dict(torch.load("model.pth"))
```

* ä¿å­˜çš„æ˜¯ **æ¨¡å‹å‚æ•°å­—å…¸**ï¼Œä¸åŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ã€‚
* è‹¥è¦å®Œæ•´æ¢å¤è®­ç»ƒï¼Œè¿˜éœ€ä¿å­˜ `optimizer.state_dict()`ã€‚

---














