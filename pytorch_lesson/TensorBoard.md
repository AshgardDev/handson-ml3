éå¸¸å¥½ ğŸ‘ ä½ é—®çš„è¿™ä¸ªæ˜¯ PyTorch è®­ç»ƒä¸­æœ€å¸¸ç”¨çš„å¯è§†åŒ–å·¥å…·ä¹‹ä¸€ã€‚
æˆ‘ä»¬ä¸€æ­¥æ­¥è®²æ¸…æ¥šâ€”â€”å¦‚ä½•ç”¨ **TensorBoard**ï¼ˆå®˜æ–¹æ”¯æŒï¼‰æ¥å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚

---

## ğŸ§© ä¸€ã€å®‰è£…

```bash
pip install tensorboard
```

å¦‚æœä½ æƒ³å…¼å®¹æ—§é¡¹ç›®ï¼ˆæ¯”å¦‚ä»¥å‰ç”¨ `tensorboardX`ï¼‰ï¼Œå¯ä»¥é¢å¤–è£…ä¸Šï¼š

```bash
pip install tensorboardX
```

---

## ğŸ§  äºŒã€åœ¨ PyTorch ä¸­ä½¿ç”¨ï¼ˆæ¨èå®˜æ–¹æ¥å£ï¼‰

å®˜æ–¹æ¥å£åœ¨ `torch.utils.tensorboard`ï¼ŒAPI ä¸ `tensorboardX` å®Œå…¨ä¸€è‡´ã€‚

### âœ… åŸºæœ¬ç¤ºä¾‹

```python
from torch.utils.tensorboard import SummaryWriter
import torch
import numpy as np

# 1ï¸âƒ£ åˆ›å»ºæ—¥å¿—ç›®å½•ï¼ˆæ‰€æœ‰è®°å½•éƒ½ä¼šå†™åˆ°è¿™é‡Œï¼‰
writer = SummaryWriter(log_dir='./runs/experiment1')

# 2ï¸âƒ£ æ·»åŠ æ ‡é‡ï¼ˆæœ€å¸¸ç”¨ï¼šloss, accï¼‰
for step in range(100):
    writer.add_scalar('Loss/train', np.random.random(), step)
    writer.add_scalar('Accuracy/train', np.random.random(), step)

# 3ï¸âƒ£ æ·»åŠ å›¾åƒ
images = torch.rand(4, 3, 28, 28)
writer.add_images('InputImages', images)

# 4ï¸âƒ£ æ·»åŠ æƒé‡ç›´æ–¹å›¾
weights = torch.randn(100)
writer.add_histogram('Layer1/weights', weights, 0)

# 5ï¸âƒ£ æ·»åŠ æ¨¡å‹è®¡ç®—å›¾
import torch.nn as nn
model = nn.Sequential(
    nn.Conv2d(1, 16, 3),
    nn.ReLU(),
    nn.Flatten(),
    nn.Linear(26*26*16, 10)
)
x = torch.randn(1, 1, 28, 28)
writer.add_graph(model, x)

writer.close()
```

---

## ğŸš€ ä¸‰ã€å¯åŠ¨ TensorBoard

è¿è¡Œå‘½ä»¤ï¼š

```bash
tensorboard --logdir=./runs
```

æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š

> [http://localhost:6006](http://localhost:6006)

---

## ğŸ“Š å››ã€TensorBoard å¸¸è§å¯è§†åŒ–å†…å®¹

| ç±»å‹   | API                                                                     | ç”¨é€”                  |
| ---- | ----------------------------------------------------------------------- | ------------------- |
| æ ‡é‡   | `add_scalar(tag, value, step)`                                          | lossã€accuracyã€lr    |
| å¤šä¸ªæ ‡é‡ | `add_scalars(main_tag, {'train':v1, 'val':v2}, step)`                   | å¯¹æ¯” train vs val     |
| å›¾åƒ   | `add_image(tag, img_tensor, step)` / `add_images(tag, img_batch, step)` | è¾“å…¥æ ·æœ¬æˆ–ç»“æœ             |
| ç›´æ–¹å›¾  | `add_histogram(tag, values, step)`                                      | å‚æ•°åˆ†å¸ƒå˜åŒ–              |
| è®¡ç®—å›¾  | `add_graph(model, input_tensor)`                                        | å¯è§†åŒ–æ¨¡å‹ç»“æ„             |
| æ–‡æœ¬   | `add_text(tag, text_string, step)`                                      | è®­ç»ƒæ—¥å¿—æˆ–å¤‡æ³¨             |
| åµŒå…¥   | `add_embedding(features, metadata, label_img)`                          | t-SNE/embedding å¯è§†åŒ– |

---

## ğŸ§© äº”ã€é›†æˆåˆ°è®­ç»ƒå¾ªç¯ä¸­ï¼ˆå®Œæ•´ç¤ºä¾‹ï¼‰

ä¸‹é¢æ˜¯ä¸€ä¸ªå…¸å‹çš„ MNIST è®­ç»ƒ + TensorBoard è®°å½•æµç¨‹ï¼š

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# 1ï¸âƒ£ æ•°æ®
transform = transforms.ToTensor()
trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
trainloader = DataLoader(trainset, batch_size=64, shuffle=True)

# 2ï¸âƒ£ æ¨¡å‹
model = nn.Sequential(
    nn.Conv2d(1, 16, 3, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Flatten(),
    nn.Linear(16*14*14, 10)
)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 3ï¸âƒ£ TensorBoard
writer = SummaryWriter('./runs/mnist_demo')

# 4ï¸âƒ£ è®­ç»ƒå¾ªç¯
for epoch in range(5):
    running_loss = 0.0
    for i, (images, labels) in enumerate(trainloader):
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    avg_loss = running_loss / len(trainloader)
    writer.add_scalar('Loss/train', avg_loss, epoch)
    print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}')

# 5ï¸âƒ£ ä¿å­˜æ¨¡å‹ç»“æ„
sample_input = torch.randn(1, 1, 28, 28)
writer.add_graph(model, sample_input)

writer.close()
```

è¿è¡Œåå†æ‰§è¡Œï¼š

```bash
tensorboard --logdir=./runs
```

---

## ğŸ’¡ å…­ã€å®ç”¨æŠ€å·§

* ğŸ§® å¯ä»¥ç”¨ä¸åŒçš„ `log_dir` åŒºåˆ†å®éªŒï¼ˆå¦‚ `runs/exp1_lr_0.01`, `runs/exp2_lr_0.001`ï¼‰
* ğŸ” æ”¯æŒå¤šä¸ªå®éªŒæ›²çº¿åŒæ—¶å¯¹æ¯”
* ğŸ§  æ”¯æŒè®°å½•å­¦ä¹ ç‡å˜åŒ–æ›²çº¿ï¼ˆé€‚é… Schedulerï¼‰

---

æ˜¯å¦å¸Œæœ›æˆ‘å¸®ä½ æŠŠ **TensorBoard å¯è§†åŒ–** æ•´åˆè¿› â€œæ·±åº¦å¯åˆ†ç¦»è†¨èƒ€å·ç§¯ MNISTâ€ çš„ä»£ç ç‰ˆæœ¬ï¼Ÿé‚£æ ·ä½ å¯ä»¥å®æ—¶çœ‹åˆ° lossã€accuracyã€feature map çš„å›¾åƒã€‚
