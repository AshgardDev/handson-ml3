


å¥½é—®é¢˜ï¼`nn.Parameter` æ˜¯ PyTorch é‡Œéå¸¸æ ¸å¿ƒçš„æ¦‚å¿µï¼Œç†è§£å®ƒçš„ç»“æ„èƒ½å¸®ä½ å½»åº•ææ¸…æ¥šå‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨ä¹‹é—´çš„å…³ç³»ã€‚

---

## ğŸ— `nn.Parameter` çš„æœ¬è´¨

æºç ä½ç½®ï¼š`torch/nn/parameter.py`
ç®€åŒ–åæ ¸å¿ƒå®ç°å¤§è‡´å¦‚ä¸‹ï¼š

```python
import torch

class Parameter(torch.Tensor):
    def __new__(cls, data=None, requires_grad=True):
        # Parameter æ˜¯ Tensor çš„å­ç±»
        # ç›´æ¥ç”¨ Tensor çš„ __new__ åˆ›å»ºåº•å±‚å­˜å‚¨
        return torch.Tensor._make_subclass(cls, data, requires_grad)

    def __repr__(self):
        return f"Parameter containing:\n{super().__repr__()}"
```

æ‰€ä»¥ï¼š

* `nn.Parameter` æœ¬è´¨å°±æ˜¯ä¸€ä¸ª **å¸¦æ ‡è®°çš„ Tensor**ï¼Œè¡¨ç¤ºâ€œè¿™æ˜¯ä¸€ä¸ªè¦è®­ç»ƒçš„å‚æ•°â€
* å®ƒç»§æ‰¿è‡ª `torch.Tensor`ï¼Œæ‰€ä»¥æœ‰æ‰€æœ‰ Tensor çš„å±æ€§å’Œæ–¹æ³•
* å®ƒæœ‰ä¸€ä¸ªå¾ˆå…³é”®çš„ flag â€”â€” `requires_grad=True`ï¼Œç¡®ä¿ autograd ä¼šè¿½è¸ªå®ƒ
* å½“å®ƒè¢«æ”¾åˆ° `nn.Module` é‡Œä½œä¸ºå±æ€§æ—¶ï¼Œ`model.parameters()` ä¼šè‡ªåŠ¨æ‰¾åˆ°å®ƒ

---

## ğŸ”‘ æ ¸å¿ƒå­—æ®µ

ä¸€ä¸ª `nn.Parameter` å¯¹è±¡æœ‰å‡ ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼š

| å­—æ®µ / å±æ€§                    | è¯´æ˜                                                                    |
| -------------------------- | --------------------------------------------------------------------- |
| **data**                   | å‚æ•°çš„æ•°å€¼æœ¬ä½“ï¼ˆå°±æ˜¯ä¸€ä¸ªæ™®é€š `Tensor`ï¼‰ï¼Œä¼˜åŒ–å™¨æ›´æ–°æ—¶å°±æ˜¯æ”¹è¿™ä¸ª                                  |
| **grad**                   | åå‘ä¼ æ’­åå­˜æ”¾æ¢¯åº¦çš„åœ°æ–¹ï¼Œç±»å‹ä¹Ÿæ˜¯ Tensorï¼Œç¬¬ä¸€æ¬¡ backward åæ‰ä¼šåˆ†é…                           |
| **requires\_grad**         | æ˜¯å¦å‚ä¸æ¢¯åº¦è®¡ç®—ï¼Œé»˜è®¤ True                                                      |
| **is\_leaf**               | æ˜¯å¦æ˜¯è®¡ç®—å›¾çš„å¶å­èŠ‚ç‚¹ï¼Œé€šå¸¸ Parameter æ˜¯å¶å­èŠ‚ç‚¹                                        |
| **grad\_fn**               | å¦‚æœ requires\_grad=True ä¸”ä¸æ˜¯å¶å­èŠ‚ç‚¹ï¼Œä¼šæŒ‡å‘ç”Ÿæˆè¯¥å¼ é‡çš„å‡½æ•°ï¼›Parameter é€šå¸¸ grad\_fn=None |
| **dtype / device / shape** | å’Œæ™®é€š Tensor ä¸€æ ·ï¼Œæè¿°æ•°æ®ç±»å‹ã€è®¾å¤‡ã€å½¢çŠ¶                                            |

---

## ğŸ§  ç›´è§‚ç†è§£

æˆ‘ä»¬å¯ä»¥æŠŠ `nn.Parameter` çœ‹ä½œæ˜¯ä¸€ä¸ªâ€œå¸¦æ ‡è®°çš„ Tensorâ€ï¼Œè¿™ä¸ªæ ‡è®°å‘Šè¯‰ `nn.Module` å’Œ `Optimizer`ï¼š

> â€œå˜¿ï¼Œè¿™æ˜¯ä¸€ä¸ªå¯è®­ç»ƒçš„å‚æ•°ï¼Œåˆ«å¿˜äº†åœ¨ backward ä¹‹åç”¨æ¢¯åº¦æ›´æ–°å®ƒï¼â€

---

## ğŸ” ä»£ç éªŒè¯

ä½ å¯ä»¥ç›´æ¥åœ¨ Python é‡Œçœ‹ä¸€ä¸ª Parameter çš„ç»“æ„ï¼š

```python
import torch
import torch.nn as nn

p = nn.Parameter(torch.randn(3, 4))
print(p)
print("data:", p.data)
print("grad:", p.grad)
print("requires_grad:", p.requires_grad)
print("is_leaf:", p.is_leaf)
print("grad_fn:", p.grad_fn)
```

è¾“å‡ºç±»ä¼¼ï¼š

```
Parameter containing:
tensor([[-1.1510,  0.2936,  0.2095,  0.7886],
        [ 0.5672, -0.7861, -0.2347,  0.9654],
        [-0.2063, -1.0667, -0.4358,  0.6723]], requires_grad=True)
data: tensor([...])
grad: None
requires_grad: True
is_leaf: True
grad_fn: None
```

---

## ğŸ”— å’Œæ™®é€š Tensor çš„åŒºåˆ«

| ç‰¹æ€§                           | æ™®é€š Tensor | nn.Parameter |
| ---------------------------- | --------- | ------------ |
| æ˜¯å¦ä¼šè¢« `model.parameters()` éå† | âŒ ä¸ä¼š      | âœ… ä¼š          |
| é»˜è®¤ `requires_grad`           | False     | True         |
| å…¸å‹ç”¨é€”                         | è®¡ç®—ä¸­é—´ç»“æœ    | ä½œä¸ºå¯è®­ç»ƒå‚æ•°      |

ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ å®Œå…¨å¯ä»¥ä¸ç”¨ `nn.Parameter`ï¼Œç›´æ¥ç”¨ `requires_grad=True` çš„ Tensor æ‰‹åŠ¨ç®¡ç†ä¼˜åŒ–ï¼Œä½† PyTorch çš„ `nn.Module` + `Optimizer` ç”Ÿæ€å°±æ˜¯ä¸“é—¨ä¸º `nn.Parameter` ä¼˜åŒ–çš„ï¼Œæ‰€ä»¥æ¨èç”¨å®ƒã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼  `nn.Parameter` çš„ç»“æ„å›¾ï¼ŒæŠŠ `data`ã€`grad`ã€`requires_grad`ã€`grad_fn` ç­‰å­—æ®µç›´è§‚åœ°å±•ç¤ºå‡ºæ¥ï¼Ÿè¿™æ ·ä½ èƒ½ä¸€ä¸‹å­çœ‹æ‡‚å®ƒå’Œæ™®é€š Tensor çš„åŒºåˆ«ã€‚





éå¸¸å¥½çš„é—®é¢˜ï¼PyTorch çš„ `torch.Tensor` æ˜¯æ ¸å¿ƒæ•°æ®ç»“æ„ï¼Œå®ƒæœ‰å¾ˆå¤šå±æ€§ï¼Œå…¶ä¸­æœ‰äº›æ˜¯è·Ÿ **æ•°æ®å­˜å‚¨** æœ‰å…³ï¼Œæœ‰äº›æ˜¯è·Ÿ **è®¡ç®—å›¾å’Œè‡ªåŠ¨æ±‚å¯¼** æœ‰å…³ã€‚ç†è§£è¿™äº›å±æ€§èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°è°ƒè¯•ã€å†™æ¨¡å‹ã€‚

æˆ‘å¸®ä½ åˆ†æˆä¸¤ç±»è®²ï¼š**æ•°æ®ç›¸å…³å±æ€§** å’Œ **autogradç›¸å…³å±æ€§**ã€‚

---

## ğŸ— 1. æ•°æ®ç›¸å…³å±æ€§ï¼ˆæè¿°å¼ é‡æœ¬èº«ï¼‰

è¿™äº›å±æ€§å’Œ NumPy çš„ `ndarray` ç±»ä¼¼ï¼Œç”¨æ¥æè¿°å¼ é‡çš„å½¢çŠ¶ã€ç±»å‹ã€è®¾å¤‡ç­‰ï¼š

| å±æ€§                           | è¯´æ˜                        | ç¤ºä¾‹                             |
| ---------------------------- | ------------------------- | ------------------------------ |
| **shape** / **size()**       | å¼ é‡çš„å½¢çŠ¶ï¼ˆè¿”å› `torch.Size` å¯¹è±¡ï¼‰ | `x.shape â†’ torch.Size([2, 3])` |
| **dtype**                    | æ•°æ®ç±»å‹                      | `torch.float32`, `torch.int64` |
| **device**                   | å­˜å‚¨è®¾å¤‡                      | `cpu`, `cuda:0`                |
| **layout**                   | å­˜å‚¨å¸ƒå±€                      | ä¸€èˆ¬æ˜¯ `torch.strided`ï¼Œä¹Ÿæ”¯æŒç¨€ç–å¸ƒå±€    |
| **ndimension()** / **dim()** | å¼ é‡ç»´åº¦æ•°                     | `x.dim() â†’ 2`                  |
| **numel()**                  | å…ƒç´ æ€»æ•°                      | `x.numel() â†’ 6`                |
| **requires\_grad**           | æ˜¯å¦éœ€è¦æ¢¯åº¦ï¼ˆboolï¼‰              | True / False                   |
| **is\_leaf**                 | æ˜¯å¦æ˜¯è®¡ç®—å›¾å¶å­èŠ‚ç‚¹                | True / False                   |
| **is\_contiguous()**         | å†…å­˜æ˜¯å¦è¿ç»­                    | å½±å“æ€§èƒ½                           |
| **stride()**                 | æ¯ä¸ªç»´åº¦æ­¥é•¿                    | å†…å­˜è®¿é—®æ–¹å¼                         |

---

## ğŸ§  2. Autograd ç›¸å…³å±æ€§ï¼ˆä¸è®¡ç®—å›¾å’Œæ¢¯åº¦æœ‰å…³ï¼‰

| å±æ€§                 | è¯´æ˜                       | ç¤ºä¾‹            |
| ------------------ | ------------------------ | ------------- |
| **grad**           | è¯¥å¼ é‡çš„æ¢¯åº¦ï¼ˆä¹Ÿæ˜¯ä¸€ä¸ªå¼ é‡ï¼‰           | backward åæ‰æœ‰å€¼ |
| **grad\_fn**       | ç”Ÿæˆè¯¥å¼ é‡çš„ `Function`ï¼ˆè®¡ç®—å›¾èŠ‚ç‚¹ï¼‰ | å¶å­èŠ‚ç‚¹ä¸º None    |
| **requires\_grad** | æ˜¯å¦è¿½è¸ªæ¢¯åº¦                   | æ¨¡å‹å‚æ•°é€šå¸¸ä¸º True  |
| **retain\_grad()** | å¯¹éå¶å­èŠ‚ç‚¹ä¿ç•™æ¢¯åº¦               | ç”¨äºè°ƒè¯•æˆ–ä¸­é—´æ¢¯åº¦è®¡ç®—   |

---

## ğŸ§ª ç¤ºä¾‹ä»£ç 

ä½ å¯ä»¥ç›´æ¥åœ¨ Python é‡Œå®éªŒï¼š

```python
import torch

x = torch.randn(2, 3, requires_grad=True)
y = x * 2 + 1

print("=== x çš„å±æ€§ ===")
print("shape:", x.shape)
print("dtype:", x.dtype)
print("device:", x.device)
print("requires_grad:", x.requires_grad)
print("is_leaf:", x.is_leaf)
print("grad:", x.grad)
print("grad_fn:", x.grad_fn)

print("\n=== y çš„å±æ€§ ===")
print("is_leaf:", y.is_leaf)
print("grad_fn:", y.grad_fn)
```

å¯èƒ½è¾“å‡ºï¼š

```
=== x çš„å±æ€§ ===
shape: torch.Size([2, 3])
dtype: torch.float32
device: cpu
requires_grad: True
is_leaf: True
grad: None
grad_fn: None

=== y çš„å±æ€§ ===
is_leaf: False
grad_fn: <AddBackward0 object at 0x...>
```

è¯´æ˜ï¼š

* `x` æ˜¯å¶å­èŠ‚ç‚¹ï¼ˆç”¨æˆ·åˆ›å»ºï¼Œrequires\_grad=Trueï¼‰
* `y` æ˜¯è®¡ç®—ç»“æœï¼Œæœ‰ `grad_fn`ï¼Œä¸æ˜¯å¶å­èŠ‚ç‚¹

---

## ğŸ¯ æ€»ç»“

### ğŸ”‘ æœ€å¸¸ç”¨çš„ Tensor å±æ€§

* **å½¢çŠ¶**ï¼š`x.shape`
* **æ•°æ®ç±»å‹**ï¼š`x.dtype`
* **è®¾å¤‡**ï¼š`x.device`
* **æ˜¯å¦æ±‚æ¢¯åº¦**ï¼š`x.requires_grad`
* **æ¢¯åº¦å€¼**ï¼š`x.grad`
* **è®¡ç®—å›¾èŠ‚ç‚¹**ï¼š`x.grad_fn`
* **æ˜¯å¦å¶å­èŠ‚ç‚¹**ï¼š`x.is_leaf`

è¿™äº›å±æ€§åŸºæœ¬ä¸Šèƒ½æ»¡è¶³ä½ è°ƒè¯•ç»å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ¨¡å‹çš„éœ€æ±‚ã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼ â€œTensor å†…éƒ¨ç»“æ„å›¾â€ï¼ŒæŠŠ **data**ã€**grad**ã€**grad\_fn**ã€**requires\_grad**ã€**device** ç­‰å­—æ®µæ”¾åœ¨ä¸€ä¸ªå›¾é‡Œï¼Œè®©ä½ ç›´è§‚çœ‹åˆ° Tensor é‡Œéƒ½å­˜äº†å“ªäº›ä¸œè¥¿ï¼Ÿ





éå¸¸å¥½ï¼æˆ‘ä»¬æŠŠ **`torch.nn.Parameter`** å’Œ **`torch.Tensor`** ç›´æ¥å¯¹æ¯”ä¸€ä¸‹ï¼Œä½ å°±èƒ½æ¸…æ™°åœ°çœ‹åˆ°åŒºåˆ«å’Œè”ç³»äº†ã€‚

---

## ğŸ”‘ 1. `Tensor` vs `Parameter` æ ¸å¿ƒåŒºåˆ«

| ç‰¹æ€§                 | `torch.Tensor` | `torch.nn.Parameter`                              |
| ------------------ | -------------- | ------------------------------------------------- |
| **æœ¬è´¨**             | ä»»æ„å¤šç»´æ•°ç»„         | ç»§æ‰¿è‡ª `Tensor` çš„ç‰¹æ®Šå­ç±»                                |
| **ç”¨é€”**             | ä¸€èˆ¬å­˜å‚¨æ•°æ®æˆ–ä¸­é—´è®¡ç®—ç»“æœ  | ä¸“é—¨ç”¨æ¥å­˜å‚¨**å¯å­¦ä¹ å‚æ•°**                                   |
| **requires\_grad** | é»˜è®¤ `False`     | **é»˜è®¤ True**                                       |
| **è‡ªåŠ¨æ³¨å†Œåˆ°æ¨¡å‹**        | âŒ ä¸ä¼šè‡ªåŠ¨æ³¨å†Œ       | âœ… ä½œä¸º `nn.Module` å±æ€§èµ‹å€¼æ—¶ï¼Œä¼šè‡ªåŠ¨åŠ å…¥ `model.parameters()` |
| **å‡ºç°åœ¨ä¼˜åŒ–å™¨é‡Œ**        | âŒ é™¤éæ‰‹åŠ¨ä¼ è¿›å»      | âœ… è‡ªåŠ¨å‡ºç°åœ¨ä¼˜åŒ–å™¨å‚æ•°åˆ—è¡¨ä¸­                                   |
| **å¸¸è§åœºæ™¯**           | è¾“å…¥æ•°æ®ã€ä¸´æ—¶å˜é‡      | æƒé‡ã€åç½®ã€å¯è®­ç»ƒè¶…å‚æ•°                                      |

---

## ğŸ— 2. Parameter çš„å†…éƒ¨ç»“æ„

`Parameter` å…¶å®å°±æ˜¯ä¸€ä¸ªç‰¹æ®Šçš„ `Tensor`ï¼Œæºç éå¸¸ç®€çŸ­ï¼ˆPyTorch æºç ç²¾ç®€ç‰ˆï¼‰ï¼š

```python
class Parameter(torch.Tensor):
    def __new__(cls, data=None, requires_grad=True):
        return torch.Tensor._make_subclass(cls, data, requires_grad)
```

ä½ å¯ä»¥çœ‹åˆ°ï¼š

* å®ƒ **ç»§æ‰¿è‡ª Tensor**
* åªæ˜¯å¼ºåˆ¶ `requires_grad=True`
* å½“ä½ æŠŠ `Parameter` ä½œä¸º `nn.Module` çš„å±æ€§æ—¶ï¼Œå®ƒä¼šè¢«è‡ªåŠ¨æ³¨å†Œåˆ°æ¨¡å—çš„ `_parameters` å­—å…¸

---

## ğŸ§ª å®ä¾‹å¯¹æ¯”

```python
import torch
import torch.nn as nn

# æ™®é€š Tensor
w1 = torch.randn(3, 3, requires_grad=True)

# Parameter
w2 = nn.Parameter(torch.randn(3, 3))

print("w1 ç±»å‹:", type(w1))
print("w2 ç±»å‹:", type(w2))
print("w1 æ˜¯å¦æ³¨å†Œä¸ºå‚æ•°:", hasattr(w1, '_is_param'))
print("w2 æ˜¯å¦æ³¨å†Œä¸ºå‚æ•°:", hasattr(w2, '_is_param'))
```

è¾“å‡ºå¯èƒ½æ˜¯ï¼š

```
w1 ç±»å‹: <class 'torch.Tensor'>
w2 ç±»å‹: <class 'torch.nn.parameter.Parameter'>
w1 æ˜¯å¦æ³¨å†Œä¸ºå‚æ•°: False
w2 æ˜¯å¦æ³¨å†Œä¸ºå‚æ•°: True
```

---

## ğŸ§  3. åœ¨æ¨¡å‹ä¸­çš„è¡Œä¸ºå¯¹æ¯”

```python
class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.w_param = nn.Parameter(torch.randn(3, 3))  # è‡ªåŠ¨æ³¨å†Œ
        self.w_tensor = torch.randn(3, 3, requires_grad=True)  # ä¸ä¼šæ³¨å†Œ

model = MyModel()
print(list(model.parameters()))  # åªæœ‰ w_param
```

ä½ ä¼šå‘ç°ï¼š

* `w_param` å‡ºç°åœ¨ `model.parameters()` ä¸­
* `w_tensor` **ä¸ä¼š** å‡ºç°åœ¨é‡Œé¢ï¼ˆé™¤éä½ æ‰‹åŠ¨æŠŠå®ƒä¼ ç»™ optimizerï¼‰

---

## ğŸ¯ æ€»ç»“ï¼ˆå¯¹æ¯”å›¾ï¼‰

```
Tensor
 â”œâ”€â”€ data (å­˜å‚¨æ•°å€¼)
 â”œâ”€â”€ requires_grad (é»˜è®¤ False)
 â”œâ”€â”€ grad (æ¢¯åº¦ï¼Œåå‘ä¼ æ’­åå¡«å……)
 â””â”€â”€ grad_fn (è®¡ç®—å›¾èŠ‚ç‚¹ï¼Œå¶å­èŠ‚ç‚¹ä¸º None)

Parameter (ç»§æ‰¿ Tensor)
 â”œâ”€â”€ data (å­˜å‚¨å¯å­¦ä¹ å‚æ•°)
 â”œâ”€â”€ requires_grad (å¼ºåˆ¶ True)
 â”œâ”€â”€ grad (æ¢¯åº¦)
 â”œâ”€â”€ grad_fn
 â””â”€â”€ _is_param=True (ä½¿å…¶è¢« nn.Module è‡ªåŠ¨æ³¨å†Œ)
```

âœ… **ç»“è®ºï¼š**

* `Parameter` = `Tensor` + **è‡ªåŠ¨æ³¨å†Œåˆ°æ¨¡å‹ + é»˜è®¤éœ€è¦æ¢¯åº¦**
* å®ƒä»¬å­˜å‚¨çš„éƒ½æ˜¯æ•°å€¼æ•°æ®ï¼Œä½† `Parameter` ä¸»è¦ç”¨äº **æ¨¡å‹æƒé‡ã€åç½®ã€å¯å­¦ä¹ å˜é‡**
* å¦‚æœä½ æƒ³è®©ä¼˜åŒ–å™¨è‡ªåŠ¨æ›´æ–°æŸä¸ªå¼ é‡çš„å€¼ï¼Œå°±ç”¨ `nn.Parameter`

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼ â€œTensor vs Parameter å†…éƒ¨ç»“æ„å¯¹æ¯”å›¾â€ï¼ŒæŠŠä¸¤è€…çš„å…³é”®å±æ€§å¹¶æ’å±•ç¤ºï¼Œè®©ä½ ä¸€çœ¼çœ‹å‡ºå·®åˆ«ï¼Ÿ


å¥½é—®é¢˜ï¼è¿™æ­£æ˜¯ **`nn.Module` + `nn.Parameter` + `Optimizer`** ä¹‹é—´åä½œçš„å…³é”®æœºåˆ¶ã€‚
æˆ‘ç»™ä½ å®Œæ•´æ‹†è§£ä¸€ä¸‹ï¼Œè®©ä½ æ˜ç™½ **ä¸ºä»€ä¹ˆ `optimizer.step()` èƒ½æ›´æ–° model çš„å‚æ•°**ã€‚

---

## ğŸ— 1. `nn.Module` ä¼šè‡ªåŠ¨æ”¶é›†å‚æ•°

å½“ä½ åœ¨æ¨¡å‹é‡Œå†™ï¼š

```python
import torch
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.w = nn.Parameter(torch.randn(3, 3))  # å¯å­¦ä¹ å‚æ•°

model = MyModel()
```

å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ

1. `nn.Parameter` è¢«èµ‹å€¼ç»™ `self.w`
2. `nn.Module` çš„ `__setattr__` è¢«è§¦å‘

   * å®ƒå‘ç° `value` æ˜¯ `Parameter`
   * è‡ªåŠ¨æŠŠå®ƒæ”¾åˆ° `self._parameters` è¿™ä¸ªå­—å…¸é‡Œ

æ‰€ä»¥ `model._parameters` é‡Œå°±æœ‰ï¼š

```python
{'w': Parameter containing:
tensor([...], requires_grad=True)}
```

è°ƒç”¨ `model.parameters()` å®é™…ä¸Šå°±æ˜¯è¿­ä»£ `self._parameters.values()`ï¼Œæ‹¿åˆ°æ‰€æœ‰ `Parameter` å¯¹è±¡ã€‚

---

## ğŸ§  2. `Optimizer` ä¿å­˜å‚æ•°å¼•ç”¨

å½“ä½ åˆ›å»ºä¼˜åŒ–å™¨ï¼š

```python
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
```

* `model.parameters()` è¿”å›çš„æ˜¯ **Parameter å¯¹è±¡çš„è¿­ä»£å™¨**
* ä¼˜åŒ–å™¨æ¥æ”¶å®ƒï¼Œå¹¶æŠŠè¿™äº› Parameter çš„ **å¼•ç”¨** å­˜åˆ° `optimizer.param_groups`
* æ³¨æ„ï¼šä¸æ˜¯æ‹·è´ï¼Œæ˜¯å¼•ç”¨ï¼è¿™æ„å‘³ç€å‚æ•°æ›´æ–°æ˜¯ **å°±åœ°ä¿®æ”¹ (in-place)**

---

## ğŸ”„ 3. åå‘ä¼ æ’­ + æ¢¯åº¦æ›´æ–°æµç¨‹

1. å‰å‘è®¡ç®—ï¼š

```python
y = model.w.sum()   # å‡è®¾æŸå¤±å‡½æ•°æ˜¯è¿™ä¸ª
```

2. åå‘ä¼ æ’­ï¼š

```python
y.backward()
```

* è‡ªåŠ¨è®¡ç®— `model.w.grad`ï¼ˆæ¢¯åº¦å¼ é‡ï¼‰

3. ä¼˜åŒ–å™¨æ›´æ–°ï¼š

```python
optimizer.step()
```

SGD çš„æ ¸å¿ƒä»£ç éå¸¸ç®€å•ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š

```python
for param in self.param_groups[0]['params']:
    if param.grad is None:
        continue
    # åŸåœ°æ›´æ–°å‚æ•°
    param.data -= lr * param.grad.data
```

* **ç›´æ¥ä¿®æ”¹ param.data**ï¼Œå› ä¸º param æ˜¯ Parameterï¼Œæ˜¯å¼•ç”¨ï¼Œæ‰€ä»¥ model é‡Œçš„å€¼ç«‹åˆ»æ›´æ–°

---

## ğŸ“Š æµç¨‹å›¾ï¼ˆç®€åŒ–ï¼‰

```
             +-----------------+
             |   nn.Module     |
             |  (model)        |
             +--------+--------+
                      |
         collects nn.Parameter (æ³¨å†Œåˆ° _parameters)
                      |
              model.parameters()
                      â†“
           +---------------------+
           |  Optimizer (SGD)   |
           | param_groups[0]    |
           +---------+----------+
                     |
        references Parameter objects
                     |
                param.data â† ç›´æ¥æ›´æ–°
```

---

## ğŸ¯ å…³é”®ç‚¹æ€»ç»“

âœ… **ä¸ºä»€ä¹ˆ optimizer èƒ½æ›´æ–° model çš„å‚æ•°ï¼š**

* `nn.Module` è‡ªåŠ¨æ”¶é›† `nn.Parameter`
* `model.parameters()` è¿”å›å‚æ•°å¼•ç”¨
* ä¼˜åŒ–å™¨ä¿å­˜è¿™äº›å¼•ç”¨
* `optimizer.step()` åŸåœ°ä¿®æ”¹ `.data`
* å› ä¸ºæ˜¯å¼•ç”¨ï¼Œæ‰€ä»¥ model é‡Œç«‹åˆ»ç”Ÿæ•ˆ

âœ… **å‚æ•°å’Œæ¢¯åº¦æ˜¯ä¸¤ä¸ªä¸åŒçš„å¯¹è±¡ï¼š**

* `param.data`ï¼šå­˜å‚¨å‚æ•°çš„å€¼
* `param.grad`ï¼šå­˜å‚¨æ¢¯åº¦
* ä¼˜åŒ–å™¨ç”¨æ¢¯åº¦æ›´æ–°å‚æ•°ï¼Œç„¶åå¯ä»¥é€šè¿‡ `optimizer.zero_grad()` æ¸…ç©ºæ¢¯åº¦ï¼Œå‡†å¤‡ä¸‹ä¸€è½®

---

è¦ä¸è¦æˆ‘å¸®ä½ ç”»ä¸€å¼ æ›´è¯¦ç»†çš„å›¾ï¼ŒæŠŠ **modelã€parameterã€optimizerã€grad** å››è€…çš„å…³ç³»ç”»æˆä¸€ä¸ªå†…å­˜å¼•ç”¨å›¾ï¼Œè®©ä½ å½»åº•ææ¸…æ¥šä¼˜åŒ–å™¨æ˜¯æ€ä¹ˆä¸€æ­¥æ­¥ä¿®æ”¹å‚æ•°çš„ï¼Ÿ




éå¸¸æ•é”ï¼è¿™ä¸ªé—®é¢˜åˆ‡ä¸­äº† **`Tensor` å’Œ `autograd` çš„æ ¸å¿ƒæœºåˆ¶**ã€‚
ä¸ºä»€ä¹ˆ PyTorch æºç é‡Œç”¨ `param.grad.data`ï¼Œè€Œä¸æ˜¯ç›´æ¥ç”¨ `param.grad`ï¼Ÿ

---

## ğŸ— 1. `param.grad` å’Œ `param.grad.data` çš„åŒºåˆ«

| å±æ€§                | ç±»å‹     | å«ä¹‰                 | æ˜¯å¦å‚ä¸ autograd     |
| ----------------- | ------ | ------------------ | ----------------- |
| `param.grad`      | Tensor | **æ¢¯åº¦å¼ é‡**ï¼Œè®°å½•äº†è®¡ç®—å›¾çš„å†å² | âœ… ä¼šè¢« autograd è·Ÿè¸ª  |
| `param.grad.data` | Tensor | åŒä¸€å—å†…å­˜çš„â€œåŸå§‹æ•°æ®è§†å›¾â€     | âŒ ä¸ä¼šè¢« autograd è·Ÿè¸ª |

ä¹Ÿå°±æ˜¯è¯´ï¼š

* `param.grad` æ˜¯â€œå¸¦è®¡ç®—å›¾çš„æ¢¯åº¦â€
* `param.grad.data` æ˜¯â€œåŸå§‹æ¢¯åº¦å€¼ï¼Œä¸å¸¦è®¡ç®—å›¾â€

---

## ğŸ§  2. å¦‚æœç”¨ `param.grad`ï¼Œä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ

å‡è®¾æˆ‘ä»¬å†™ï¼š

```python
param.data -= lr * param.grad
```

è¿™ä¸€æ­¥ä¼šè¢« autograd è®°å½•æˆä¸€æ¡æ–°çš„è®¡ç®—å›¾æ“ä½œï¼š

* `param.data` å˜æˆäº†ä¸€ä¸ªæ–°çš„å¼ é‡
* ä¸‹ä¸€æ¬¡ backward æ—¶ï¼ŒPyTorch å¯èƒ½ä¼šè¯•å›¾å›æº¯è¿™ä¸€æ­¥
* ç»“æœä¼šæŠŠå‚æ•°æ›´æ–°æœ¬èº«ä¹Ÿç®—è¿›æ¢¯åº¦è®¡ç®—ï¼Œå¯¼è‡´æ¢¯åº¦æ··ä¹±

---

## ğŸƒ 3. ç”¨ `.data` å¯ä»¥ç»•è¿‡ autograd

`param.data` å’Œ `param.grad.data` éƒ½æ˜¯â€œåŸå§‹å­˜å‚¨è§†å›¾â€ï¼Œä¸ä¼šè¢« autograd è®°å½•ã€‚
è¿™æ ·åšçš„å¥½å¤„ï¼š

* **å°±åœ°ä¿®æ”¹å‚æ•°å€¼**
* **ä¸ç ´åè®¡ç®—å›¾**
* **ä¸‹ä¸€æ¬¡ backward åªè®¡ç®—æŸå¤±çš„æ¢¯åº¦ï¼Œä¸ä¼šå›æº¯åˆ°ä¼˜åŒ–æ­¥éª¤**

ç®€åŒ–ç‰ˆ SGD æºç ï¼š

```python
for p in params:
    if p.grad is None:
        continue
    d_p = p.grad
    p.data.add_(d_p, alpha=-lr)  # in-place ä¿®æ”¹
```

è¿™é‡Œ `p.data.add_()` æ˜¯åŸåœ°æ›´æ–°ï¼Œä¸ä¼šç”Ÿæˆæ–°çš„è®¡ç®—å›¾ã€‚

---

## ğŸ”¥ 4. å¦‚æœæƒ³è¦å¯å¾®åˆ†çš„ä¼˜åŒ–å™¨ï¼Ÿ

æœ‰æ—¶å€™ç ”ç©¶å…ƒå­¦ä¹ ã€å¯å­¦ä¹ ä¼˜åŒ–å™¨ï¼ˆå¦‚ MAMLã€å­¦ä¹ ç‡è‡ªé€‚åº”ï¼‰ï¼Œå°±**ä¸èƒ½ç”¨ `.data`**ï¼Œè€Œè¦ç”¨ `torch.no_grad()` åŒ…è£¹ï¼š

```python
with torch.no_grad():
    param -= lr * param.grad
```

è¿™èƒ½ä¿è¯ï¼š

* ä¸ç ´å autograd è®¡ç®—å›¾
* ä½†ä¿ç•™æ¢¯åº¦è®¡ç®—çš„èƒ½åŠ›ï¼ˆä¸ä¼šäº§ç”Ÿæ–°çš„å†å²è®°å½•ï¼‰

---

## ğŸ¯ å…³é”®æ€»ç»“

| ç”¨æ³•                                               | æ˜¯å¦è·Ÿè¸ªè®¡ç®—å›¾    | é€‚ç”¨åœºæ™¯                    |
| ------------------------------------------------ | ---------- | ----------------------- |
| `param -= lr * param.grad`                       | âœ… ä¼šç”Ÿæˆæ–°çš„è®¡ç®—å›¾ | ç ”ç©¶å¯å¾®åˆ†ä¼˜åŒ–å™¨æ—¶               |
| `param.data -= lr * param.grad.data`             | âŒ ä¸è·Ÿè¸ªè®¡ç®—å›¾   | **æ™®é€šè®­ç»ƒï¼Œæ ‡å‡†åšæ³•**           |
| `with torch.no_grad(): param -= lr * param.grad` | âŒ ä¸è·Ÿè¸ªè®¡ç®—å›¾   | æ¨èçš„æ›´å®‰å…¨å†™æ³•ï¼Œé¿å…ç›´æ¥æ“ä½œ `.data` |

---

âœ… **ç»“è®ºï¼š**
åœ¨æ™®é€šè®­ç»ƒä¸­ï¼Œ`param.data` / `param.grad.data` çš„åšæ³•æ˜¯ä¸ºäº†**å°±åœ°æ›´æ–°æƒé‡è€Œä¸æ±¡æŸ“è®¡ç®—å›¾**ã€‚
ç°åœ¨ PyTorch å®˜æ–¹æ¨èæ›´æ˜¾å¼çš„åšæ³•ï¼šç”¨ `torch.no_grad()` ä¿æŠ¤å‚æ•°æ›´æ–°ï¼Œè€Œä¸æ˜¯ç›´æ¥è®¿é—® `.data`ã€‚

---

è¦ä¸è¦æˆ‘å¸®ä½ æŠŠè¿™ä¸‰ç§æ›´æ–°æ–¹å¼ç”»ä¸ªå¯¹æ¯”å›¾ï¼Œå±•ç¤ºå“ªä¸€ç§ä¼šäº§ç”Ÿæ–°çš„è®¡ç®—å›¾ã€å“ªä¸€ç§ä¸ä¼šï¼Œæ–¹ä¾¿ä½ åœ¨è°ƒè¯•å…ƒå­¦ä¹ çš„æ—¶å€™é€‰å¯¹æ–¹æ³•ï¼Ÿ









